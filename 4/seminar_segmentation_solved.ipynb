{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmantation\n",
    "\n",
    "В этом занятии мы рассмотрим полный цикл подготовки модели нейронной сети для решения задачи сегментации на примере задачи [Carvana Challange](https://www.kaggle.com/c/carvana-image-masking-challenge).\n",
    "\n",
    "[Данные](https://drive.google.com/file/d/13_atfxCGnS7Qs3WYk_1h5-3RXaO5-efc/view?usp=sharing) для семинара.\n",
    "\n",
    "__В этом занятии будет:__\n",
    "\n",
    "__1. [Подготовка данных](#1.-Подготовка-данных)__\n",
    "\n",
    "__2. [Сборка модели](#2.-Сборка-модели)__\n",
    "\n",
    "__3. [Тренировка](#3.-Тренировка)__\n",
    "\n",
    "__4. [Аугментация](#4.-Аугментация)__\n",
    "\n",
    "__5. [Try Hard](#5.-Try-Hard)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting albumentations\n",
      "  Downloading albumentations-1.1.0-py3-none-any.whl (102 kB)\n",
      "Requirement already satisfied: scipy in c:\\users\\yesbol\\anaconda3\\lib\\site-packages (from albumentations) (1.6.2)\n",
      "Requirement already satisfied: numpy>=1.11.1 in c:\\users\\yesbol\\anaconda3\\lib\\site-packages (from albumentations) (1.19.5)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\yesbol\\anaconda3\\lib\\site-packages (from albumentations) (5.4.1)\n",
      "Collecting opencv-python-headless>=4.1.1\n",
      "  Downloading opencv_python_headless-4.5.4.58-cp38-cp38-win_amd64.whl (35.0 MB)\n",
      "Requirement already satisfied: scikit-image>=0.16.1 in c:\\users\\yesbol\\anaconda3\\lib\\site-packages (from albumentations) (0.18.1)\n",
      "Collecting qudida>=0.0.4\n",
      "  Downloading qudida-0.0.4-py3-none-any.whl (3.5 kB)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in c:\\users\\yesbol\\anaconda3\\lib\\site-packages (from qudida>=0.0.4->albumentations) (0.24.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\yesbol\\anaconda3\\lib\\site-packages (from qudida>=0.0.4->albumentations) (3.7.4.3)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in c:\\users\\yesbol\\anaconda3\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (3.3.4)\n",
      "Requirement already satisfied: networkx>=2.0 in c:\\users\\yesbol\\anaconda3\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (2.5)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in c:\\users\\yesbol\\anaconda3\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (8.2.0)\n",
      "Requirement already satisfied: imageio>=2.3.0 in c:\\users\\yesbol\\anaconda3\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (2.9.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in c:\\users\\yesbol\\anaconda3\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (2021.4.8)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\users\\yesbol\\anaconda3\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (1.1.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\yesbol\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\yesbol\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\yesbol\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\yesbol\\anaconda3\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (2.8.1)\n",
      "Requirement already satisfied: six in c:\\users\\yesbol\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (1.15.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\yesbol\\anaconda3\\lib\\site-packages (from networkx>=2.0->scikit-image>=0.16.1->albumentations) (5.0.6)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\yesbol\\anaconda3\\lib\\site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\yesbol\\anaconda3\\lib\\site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.0.1)\n",
      "Installing collected packages: opencv-python-headless, qudida, albumentations\n",
      "Successfully installed albumentations-1.1.0 opencv-python-headless-4.5.4.58 qudida-0.0.4\n",
      "Requirement already satisfied: opencv-python in c:\\users\\yesbol\\anaconda3\\lib\\site-packages (4.5.3.56)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\yesbol\\anaconda3\\lib\\site-packages (from opencv-python) (1.19.5)\n"
     ]
    }
   ],
   "source": [
    "# install new packages\n",
    "!pip install albumentations\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-766a008cba79>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# nn modules\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresnet50\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mResNet50\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \"\"\"\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# pylint: disable=unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtf2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# data processing\n",
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# nn modules\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.models import Model\n",
    "from keras.layers import (\n",
    "    Dense,\n",
    "    Input,\n",
    "    GlobalAveragePooling2D, \n",
    "    Dropout, \n",
    "    UpSampling2D, \n",
    "    Conv2D, \n",
    "    MaxPooling2D,\n",
    "    Concatenate,\n",
    "    Activation\n",
    ")\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Concatenate\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout, UpSampling2D, Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Подготовка данных "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_decode(mask_rle, shape):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height,width) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "    '''\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths    \n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "        \n",
    "    img = img.reshape(shape)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('input/train_masks.csv')\n",
    "print(f'Data shape: {df.shape}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make train/val dataset\n",
    "all_id = np.array(range(df.shape[0]), dtype=np.uint8)\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(all_id)\n",
    "\n",
    "split_size = 0.8\n",
    "train_df = df.loc[all_id[:int(df.shape[0] *split_size)]]\n",
    "val_df = df.loc[all_id[int(df.shape[0] * split_size):]]\n",
    "\n",
    "print(f'Train DataFrame shape: {train_df.shape}\\n'\n",
    "     f'Validation DataFrame shape: {val_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ex_num = 10\n",
    "random_id = np.random.choice(train_df.shape[0], size=ex_num, replace=False)\n",
    "\n",
    "for i, row_id in enumerate(random_id):\n",
    "    img_name, mask_rle = train_df.iloc[row_id]\n",
    "    img = cv2.imread('input/train/{}'.format(img_name))\n",
    "    w, h, _ = img.shape\n",
    "    mask = rle_decode(mask_rle, shape=(w, h, 1))\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(25, 25))\n",
    "    axes[0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))  # change colorspace for plt\n",
    "    axes[1].imshow(mask[..., 0], cmap='gray')\n",
    "    for ax in axes:\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train genrator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_generator(gen_df, batch_size=4):\n",
    "    while True:\n",
    "        x_batch = []\n",
    "        y_batch = []\n",
    "        \n",
    "        random_id = np.random.choice(gen_df.shape[0], size=batch_size, replace=False)\n",
    "        for row_id in random_id:\n",
    "            img_name, mask_rle = gen_df.iloc[row_id]\n",
    "            img = cv2.imread('input/train/{}'.format(img_name))\n",
    "            w, h, _ = img.shape\n",
    "            mask = rle_decode(mask_rle, shape=(w, h, 1))\n",
    "\n",
    "            img = cv2.resize(img, (256, 256))\n",
    "            mask = cv2.resize(mask, (256, 256))\n",
    "            \n",
    "            x_batch += [img]\n",
    "            y_batch += [mask]\n",
    "\n",
    "        x_batch = np.array(x_batch) / 255.  # normalize\n",
    "        y_batch = np.array(y_batch)\n",
    "\n",
    "        yield x_batch, np.expand_dims(y_batch, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator testing\n",
    "train_gen = keras_generator(train_df, 10)\n",
    "x, y = next(iter(train_gen))\n",
    "\n",
    "print(f'Input size: {x.shape}\\n'\n",
    "     f'Output size: {y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Сборка модели\n",
    "\n",
    "Начнем собирать первую модель для решения задачи сегментации на основе FCN\n",
    "<img src=\"https://i.ibb.co/TMwThH1/fcn.jpg\" width=\"800\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_model = VGG16(weights='imagenet', input_shape=(256,256,3), include_top=False)\n",
    "up = UpSampling2D(32, interpolation='bilinear')(vgg16_model.output)\n",
    "conv = Conv2D(1, (1, 1))(up)\n",
    "conv = Activation('sigmoid')(conv)\n",
    "\n",
    "fcn_model = Model(input=vgg16_model.input, output=conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# посмотрим на архитекутуру сети\n",
    "fcn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# тест входных и выходных размерностей модели\n",
    "test_array = np.zeros((10, 256, 256, 3), dtype='float32')\n",
    "output = fcn_model(K.variable(test_array))\n",
    "\n",
    "assert K.eval(output).shape[:3] == test_array.shape[:3], f'Incorect output shape: {K.eval(output).shape} \\\n",
    "when input shape: {test_array.shape}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_w = keras.callbacks.ModelCheckpoint('fcn_best.h5',\n",
    "                                monitor='val_loss',\n",
    "                                verbose=0,\n",
    "                                save_best_only=True,\n",
    "                                save_weights_only=True,\n",
    "                                mode='auto',\n",
    "                                period=1)\n",
    "\n",
    "last_w = keras.callbacks.ModelCheckpoint('fcn_last.h5',\n",
    "                                monitor='val_loss',\n",
    "                                verbose=0,\n",
    "                                save_best_only=False,\n",
    "                                save_weights_only=True,\n",
    "                                mode='auto',\n",
    "                                period=1)\n",
    "callbacks = [best_w, last_w]\n",
    "\n",
    "adam = keras.optimizers.Adam(lr=0.1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "fcn_model.compile(adam, 'binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Тренировка "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "train_gen = keras_generator(train_df, batch_size)\n",
    "val_gen = keras_generator(val_df, batch_size)\n",
    "\n",
    "hist = fcn_model.fit_generator(\n",
    "    train_gen,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=5,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=val_gen,\n",
    "    validation_steps=50,\n",
    "    class_weight=None,\n",
    "    max_queue_size=10,\n",
    "    workers=1,\n",
    "    use_multiprocessing=False,\n",
    "    shuffle=True,\n",
    "    initial_epoch=0,\n",
    "    verbose=1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_predicts(model, ex_num=5, th_pred=0.5):\n",
    "    random_id = np.random.choice(val_df.shape[0], size=ex_num, replace=False)\n",
    "\n",
    "    for i, row_id in enumerate(random_id):\n",
    "        img_name, mask_rle = train_df.iloc[row_id]\n",
    "        img = cv2.imread('input/train/{}'.format(img_name))\n",
    "        w, h, _ = img.shape\n",
    "        true_mask = rle_decode(mask_rle, shape=(w, h, 1))\n",
    "        pred_mask = model.predict(cv2.resize(img, (256, 256)).reshape(1, 256, 256, 3)).reshape(256, 256, 1)\n",
    "\n",
    "        fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(25, 25))\n",
    "        axes[0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))  # change colorspace for plt\n",
    "        axes[1].imshow(pred_mask[..., 0] > th_pred, cmap='gray')\n",
    "        axes[2].imshow(true_mask[..., 0], cmap='gray')\n",
    "        for ax in axes:\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predicts(fcn_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Аугментация "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations import (\n",
    "    CLAHE, RandomRotate90, Transpose, RandomCrop, Resize, ShiftScaleRotate, Blur, OpticalDistortion, \n",
    "    GridDistortion, HueSaturationValue, IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, \n",
    "    MedianBlur, IAAPiecewiseAffine, IAASharpen, IAAEmboss, RandomContrast, RandomBrightness, \n",
    "    Flip, HorizontalFlip, OneOf, Compose, PadIfNeeded, LongestMaxSize, PadIfNeeded, ElasticTransform,Cutout\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# построим функцию аугментации\n",
    "def strong_aug(p=1.0):\n",
    "    \"\"\"\n",
    "    param p: вероятность применения аугментации\n",
    "    \"\"\"\n",
    "    return Compose([\n",
    "        ShiftScaleRotate(shift_limit=0.125, scale_limit=0.2, rotate_limit=10, p=0.7, border_mode=cv2.BORDER_CONSTANT),\n",
    "        RandomCrop(256, 256),\n",
    "        #PadIfNeeded(min_height=224, min_width=224, border_mode=cv2.BORDER_CONSTANT, p=1.0),\n",
    "        #Resize(64, 64),\n",
    "        #RandomRotate90(),\n",
    "        ElasticTransform(1.), \n",
    "        #HorizontalFlip(),\n",
    "        #Cutout(p=1.),\n",
    "        #Transpose(),\n",
    "        OneOf([\n",
    "            IAAAdditiveGaussianNoise(),\n",
    "            GaussNoise(),\n",
    "        ], p=0.3),\n",
    "        OneOf([\n",
    "            MotionBlur(p=.4),\n",
    "            MedianBlur(blur_limit=3, p=0.3),\n",
    "            Blur(blur_limit=3, p=0.3),\n",
    "        ], p=0.5),\n",
    "        OneOf([\n",
    "            OpticalDistortion(p=0.3),\n",
    "            GridDistortion(p=0.1),\n",
    "            IAAPiecewiseAffine(p=0.3),\n",
    "        ], p=0.5),\n",
    "        OneOf([\n",
    "            CLAHE(clip_limit=3),\n",
    "            IAASharpen(),\n",
    "            IAAEmboss(),\n",
    "            RandomContrast(),\n",
    "            RandomBrightness(),\n",
    "        ], p=0.4),\n",
    "        HueSaturationValue(p=0.7),  \n",
    "    ],\n",
    "        p=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation = strong_aug(p=1.0)\n",
    "\n",
    "row_id = np.random.choice(val_df.shape[0], size=1, replace=False)\n",
    "img_name, mask_rle = train_df.iloc[row_id[0]]\n",
    "img = cv2.imread('input/train/{}'.format(img_name))\n",
    "w, h, _ = img.shape\n",
    "mask = rle_decode(mask_rle, shape=(w, h, 1))\n",
    "\n",
    "data = {'image': img.astype('uint8'), 'mask': mask}\n",
    "augmented = augmentation(**data)\n",
    "crop_img, crop_mask = augmented[\"image\"], augmented[\"mask\"]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 15))\n",
    "axes[0].imshow(cv2.cvtColor(crop_img, cv2.COLOR_BGR2RGB))\n",
    "axes[1].imshow(crop_mask[:,:,0], cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# построим генератор с аугментацией и посмотрим на результат тренировки модели\n",
    "\n",
    "def keras_generator_aug(gen_df, batch_size=4):\n",
    "    while True:\n",
    "        x_batch = []\n",
    "        y_batch = []\n",
    "        \n",
    "        random_id = np.random.choice(gen_df.shape[0], size=batch_size, replace=False)\n",
    "        for row_id in random_id:\n",
    "            img_name, mask_rle = gen_df.iloc[row_id]\n",
    "            img = cv2.imread('input/train/{}'.format(img_name))\n",
    "            w, h, _ = img.shape\n",
    "            mask = rle_decode(mask_rle, shape=(w, h, 1))\n",
    "\n",
    "            img = cv2.resize(img, (256, 256))\n",
    "            mask = cv2.resize(mask, (256, 256))\n",
    "            \n",
    "            augmentation = strong_aug(p=1.0)\n",
    "            data = {'image': img.astype('uint8'), 'mask': mask}\n",
    "            augmented = augmentation(**data)\n",
    "            crop_img, crop_mask = augmented[\"image\"], augmented[\"mask\"]\n",
    "            \n",
    "            x_batch += [crop_img]\n",
    "            y_batch += [crop_mask]\n",
    "\n",
    "        x_batch = np.array(x_batch) / 255.  # normalize\n",
    "        y_batch = np.array(y_batch)\n",
    "\n",
    "        yield x_batch, np.expand_dims(y_batch, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "train_gen = keras_generator_aug(train_df, batch_size)\n",
    "val_gen = keras_generator_aug(val_df, batch_size)\n",
    "\n",
    "hist = fcn_model.fit_generator(\n",
    "    train_gen,\n",
    "    steps_per_epoch=10,\n",
    "    epochs=3,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=val_gen,\n",
    "    validation_steps=5,\n",
    "    class_weight=None,\n",
    "    max_queue_size=10,\n",
    "    workers=6,\n",
    "    use_multiprocessing=True,\n",
    "    shuffle=True,\n",
    "    initial_epoch=0,\n",
    "    verbose=1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predicts(fcn_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Try Hard "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SegNet\n",
    "\n",
    "Усложним вариант модели на иерархический Upsampling. Задача - реализовать модель и посмотреть на результат. Примените аугментацию в генераторе для train.\n",
    "<img src=\"https://i.ibb.co/nL3n9Br/segnet.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input(shape=(256, 256, 3))\n",
    "\n",
    "conv_1_1 = Conv2D(32, (3, 3), padding='same')(inp)\n",
    "conv_1_1 = Activation('relu')(conv_1_1)\n",
    "\n",
    "conv_1_2 = Conv2D(32, (3, 3), padding='same')(conv_1_1)\n",
    "conv_1_2 = Activation('relu')(conv_1_2)\n",
    "\n",
    "pool_1 = MaxPooling2D(2)(conv_1_2)\n",
    "\n",
    "\n",
    "conv_2_1 = Conv2D(64, (3, 3), padding='same')(pool_1)\n",
    "conv_2_1 = Activation('relu')(conv_2_1)\n",
    "\n",
    "conv_2_2 = Conv2D(64, (3, 3), padding='same')(conv_2_1)\n",
    "conv_2_2 = Activation('relu')(conv_2_2)\n",
    "\n",
    "pool_2 = MaxPooling2D(2)(conv_2_2)\n",
    "\n",
    "\n",
    "conv_3_1 = Conv2D(128, (3, 3), padding='same')(pool_2)\n",
    "conv_3_1 = Activation('relu')(conv_3_1)\n",
    "\n",
    "conv_3_2 = Conv2D(128, (3, 3), padding='same')(conv_3_1)\n",
    "conv_3_2 = Activation('relu')(conv_3_2)\n",
    "\n",
    "pool_3 = MaxPooling2D(2)(conv_3_2)\n",
    "\n",
    "\n",
    "conv_4_1 = Conv2D(256, (3, 3), padding='same')(pool_3)\n",
    "conv_4_1 = Activation('relu')(conv_4_1)\n",
    "\n",
    "conv_4_2 = Conv2D(256, (3, 3), padding='same')(conv_4_1)\n",
    "conv_4_2 = Activation('relu')(conv_4_2)\n",
    "\n",
    "pool_4 = MaxPooling2D(2)(conv_4_2)\n",
    "\n",
    "up_1 = UpSampling2D(2, interpolation='bilinear')(pool_4)\n",
    "conv_up_1_1 = Conv2D(256, (3, 3), padding='same')(up_1)\n",
    "conv_up_1_1 = Activation('relu')(conv_up_1_1)\n",
    "\n",
    "conv_up_1_2 = Conv2D(256, (3, 3), padding='same')(conv_up_1_1)\n",
    "conv_up_1_2 = Activation('relu')(conv_up_1_2)\n",
    "\n",
    "\n",
    "up_2 = UpSampling2D(2, interpolation='bilinear')(conv_up_1_2)\n",
    "conv_up_2_1 = Conv2D(128, (3, 3), padding='same')(up_2)\n",
    "conv_up_2_1 = Activation('relu')(conv_up_2_1)\n",
    "\n",
    "conv_up_2_2 = Conv2D(128, (3, 3), padding='same')(conv_up_2_1)\n",
    "conv_up_2_2 = Activation('relu')(conv_up_2_2)\n",
    "\n",
    "\n",
    "up_3 = UpSampling2D(2, interpolation='bilinear')(conv_up_2_2)\n",
    "conv_up_3_1 = Conv2D(64, (3, 3), padding='same')(up_3)\n",
    "conv_up_3_1 = Activation('relu')(conv_up_3_1)\n",
    "\n",
    "conv_up_3_2 = Conv2D(64, (3, 3), padding='same')(conv_up_3_1)\n",
    "conv_up_3_2 = Activation('relu')(conv_up_3_2)\n",
    "\n",
    "\n",
    "\n",
    "up_4 = UpSampling2D(2, interpolation='bilinear')(conv_up_3_2)\n",
    "conv_up_4_1 = Conv2D(32, (3, 3), padding='same')(up_4)\n",
    "conv_up_4_1 = Activation('relu')(conv_up_4_1)\n",
    "\n",
    "conv_up_4_2 = Conv2D(1, (3, 3), padding='same')(conv_up_4_1)\n",
    "result = Activation('sigmoid')(conv_up_4_2)\n",
    "\n",
    "\n",
    "segnet_model = Model(inputs=inp, outputs=result)\n",
    "\n",
    "adam = keras.optimizers.Adam(lr=0.1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "segnet_model.compile(adam, 'binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "segnet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "train_gen = keras_generator_aug(train_df, batch_size)\n",
    "val_gen = keras_generator_aug(val_df, batch_size)\n",
    "\n",
    "hist = segnet_model.fit_generator(\n",
    "    train_gen,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=5,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=val_gen,\n",
    "    validation_steps=50,\n",
    "    class_weight=None,\n",
    "    max_queue_size=10,\n",
    "    workers=1,\n",
    "    use_multiprocessing=False,\n",
    "    shuffle=True,\n",
    "    initial_epoch=0,\n",
    "    verbose=1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predicts(segnet_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanila UNet\n",
    "\n",
    "Пришло время для Unet. Задача аналогична - реализовать модель и посмотреть на результат. Примените аугментацию в генераторе для train.\n",
    "<img src=\"https://i.ibb.co/wC3FxCb/unet.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Concatenate\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout, UpSampling2D, Conv2D, MaxPooling2D\n",
    "\n",
    "inp = Input(shape=(256, 256, 3))\n",
    "\n",
    "conv_1_1 = Conv2D(32, (3, 3), padding='same')(inp)\n",
    "conv_1_1 = Activation('relu')(conv_1_1)\n",
    "\n",
    "conv_1_2 = Conv2D(32, (3, 3), padding='same')(conv_1_1)\n",
    "conv_1_2 = Activation('relu')(conv_1_2)\n",
    "\n",
    "pool_1 = MaxPooling2D(2)(conv_1_2)\n",
    "\n",
    "\n",
    "conv_2_1 = Conv2D(64, (3, 3), padding='same')(pool_1)\n",
    "conv_2_1 = Activation('relu')(conv_2_1)\n",
    "\n",
    "conv_2_2 = Conv2D(64, (3, 3), padding='same')(conv_2_1)\n",
    "conv_2_2 = Activation('relu')(conv_2_2)\n",
    "\n",
    "pool_2 = MaxPooling2D(2)(conv_2_2)\n",
    "\n",
    "\n",
    "conv_3_1 = Conv2D(128, (3, 3), padding='same')(pool_2)\n",
    "conv_3_1 = Activation('relu')(conv_3_1)\n",
    "\n",
    "conv_3_2 = Conv2D(128, (3, 3), padding='same')(conv_3_1)\n",
    "conv_3_2 = Activation('relu')(conv_3_2)\n",
    "\n",
    "pool_3 = MaxPooling2D(2)(conv_3_2)\n",
    "\n",
    "\n",
    "conv_4_1 = Conv2D(256, (3, 3), padding='same')(pool_3)\n",
    "conv_4_1 = Activation('relu')(conv_4_1)\n",
    "\n",
    "conv_4_2 = Conv2D(256, (3, 3), padding='same')(conv_4_1)\n",
    "conv_4_2 = Activation('relu')(conv_4_2)\n",
    "\n",
    "pool_4 = MaxPooling2D(2)(conv_4_2)\n",
    "\n",
    "up_1 = UpSampling2D(2, interpolation='bilinear')(pool_4)\n",
    "conc_1 = Concatenate()([conv_4_2, up_1])\n",
    "\n",
    "conv_up_1_1 = Conv2D(256, (3, 3), padding='same')(conc_1)\n",
    "conv_up_1_1 = Activation('relu')(conv_up_1_1)\n",
    "\n",
    "conv_up_1_2 = Conv2D(256, (3, 3), padding='same')(conv_up_1_1)\n",
    "conv_up_1_2 = Activation('relu')(conv_up_1_2)\n",
    "\n",
    "\n",
    "up_2 = UpSampling2D(2, interpolation='bilinear')(conv_up_1_2)\n",
    "conc_2 = Concatenate()([conv_3_2, up_2])\n",
    "X\n",
    "conv_up_2_1 = Conv2D(128, (3, 3), padding='same')(conc_2)\n",
    "conv_up_2_1 = Activation('relu')(conv_up_2_1)\n",
    "\n",
    "conv_up_2_2 = Conv2D(128, (3, 3), padding='same')(conv_up_2_1)\n",
    "conv_up_2_2 = Activation('relu')(conv_up_2_2)\n",
    "\n",
    "\n",
    "up_3 = UpSampling2D(2, interpolation='bilinear')(conv_up_2_2)\n",
    "conc_3 = Concatenate()([conv_2_2, up_3])\n",
    "\n",
    "conv_up_3_1 = Conv2D(64, (3, 3), padding='same')(conc_3)\n",
    "conv_up_3_1 = Activation('relu')(conv_up_3_1)\n",
    "\n",
    "conv_up_3_2 = Conv2D(64, (3, 3), padding='same')(conv_up_3_1)\n",
    "conv_up_3_2 = Activation('relu')(conv_up_3_2)\n",
    "\n",
    "\n",
    "\n",
    "up_4 = UpSampling2D(2, interpolation='bilinear')(conv_up_3_2)\n",
    "conc_4 = Concatenate()([conv_1_2, up_4])\n",
    "conv_up_4_1 = Conv2D(32, (3, 3), padding='same')(conc_4)\n",
    "conv_up_4_1 = Activation('relu')(conv_up_4_1)\n",
    "\n",
    "conv_up_4_2 = Conv2D(1, (3, 3), padding='same')(conv_up_4_1)\n",
    "result = Activation('sigmoid')(conv_up_4_2)\n",
    "\n",
    "\n",
    "unet_model = Model(inputs=inp, outputs=result)\n",
    "\n",
    "adam = keras.optimizers.Adam(lr=0.1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "unet_model.compile(adam, 'binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "train_gen = keras_generator_aug(train_df, batch_size)\n",
    "val_gen = keras_generator_aug(val_df, batch_size)\n",
    "\n",
    "hist = unet_model.fit_generator(\n",
    "    train_gen,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=5,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=val_gen,\n",
    "    validation_steps=50,\n",
    "    class_weight=None,\n",
    "    max_queue_size=10,\n",
    "    workers=1,\n",
    "    use_multiprocessing=False,\n",
    "    shuffle=True,\n",
    "    initial_epoch=0,\n",
    "    verbose=1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predicts(unet_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
